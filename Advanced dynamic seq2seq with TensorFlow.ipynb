{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e6c65646d9d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "tf.__version__\n",
    "python.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape = (None,), dtype = tf.int32, name = 'encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype = tf.int32, name = 'decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Embeddings\n",
    "\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype = tf.float32)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw = LSTMCell(encoder_hidden_units),\n",
    "                                    cell_bw = LSTMCell(encoder_hidden_units),\n",
    "                                    inputs = encoder_inputs_embedded, \n",
    "                                    sequence_length = encoder_inputs_length, \n",
    "                                    dtype = tf.float32, time_major = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ReverseSequence:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c = encoder_final_state_c,\n",
    "    h = encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length +3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype = tf.float32)\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert EOS == 1 and PAD ==0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype = tf.int32, name = 'EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype = tf.int32, name = 'PAD')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)\n",
    "    initial_input = eos_step_embedded\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None\n",
    "    return (initial_elements_finished,\n",
    "           initial_input,\n",
    "           initial_cell_state,\n",
    "           initial_cell_output,\n",
    "           initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "    \n",
    "    def get_next_input():\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        prediction = tf.argmax(output_logits, axis =1)\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths)\n",
    "    \n",
    "    finished = tf.reduce_all(elements_finished)\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "    \n",
    "    return (elements_finished,\n",
    "           input,\n",
    "           state,\n",
    "           output,\n",
    "           loop_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "    \n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 40) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer\n",
    "\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "labels = tf.one_hot(decoder_targets, depth = vocab_size, dtype = tf.float32),\n",
    "logits = decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[5, 6, 6, 2, 8]\n",
      "[4, 3, 3, 8, 4, 5]\n",
      "[4, 9, 4]\n",
      "[3, 3, 6, 7, 9, 5, 6]\n",
      "[7, 3, 4, 7, 2, 4]\n",
      "[8, 9, 2, 2, 5, 4, 2, 7]\n",
      "[9, 3, 2]\n",
      "[2, 9, 5, 4, 3, 4, 4]\n",
      "[9, 9, 4, 8, 8, 7, 5, 6]\n",
      "[4, 9, 2]\n"
     ]
    }
   ],
   "source": [
    "#training on the Toy task\n",
    "import helpers\n",
    "batch_size = 100\n",
    "batches = helpers.random_sequences(length_from=3, length_to = 8,\n",
    "                                  vocab_lower =2, vocab_upper = 10,\n",
    "                                  batch_size = batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return{\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.396998882293701\n",
      "  sample 1\n",
      "    input    > [2 4 4 3 7 0 0 0]\n",
      "    predicted> [9 3 3 3 3 3 3 3 0 0 0]\n",
      "  sample 2\n",
      "    input    > [8 2 8 7 9 0 0 0]\n",
      "    predicted> [9 5 5 0 5 0 6 7 0 0 0]\n",
      "  sample 3\n",
      "    input    > [3 5 5 3 8 2 8 3]\n",
      "    predicted> [4 4 4 4 4 4 4 4 4 4 5]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.4686514437198639\n",
      "  sample 1\n",
      "    input    > [4 7 4 7 6 2 8 0]\n",
      "    predicted> [4 7 4 7 6 2 8 1 0 0 0]\n",
      "  sample 2\n",
      "    input    > [5 6 5 4 5 0 0 0]\n",
      "    predicted> [5 6 5 4 5 1 0 0 0 0 0]\n",
      "  sample 3\n",
      "    input    > [8 5 9 7 3 6 6 0]\n",
      "    predicted> [8 5 5 7 3 6 6 1 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.19290466606616974\n",
      "  sample 1\n",
      "    input    > [5 9 2 7 0 0 0 0]\n",
      "    predicted> [5 9 2 7 1 0 0 0 0 0 0]\n",
      "  sample 2\n",
      "    input    > [9 6 2 0 0 0 0 0]\n",
      "    predicted> [9 6 2 1 0 0 0 0 0 0 0]\n",
      "  sample 3\n",
      "    input    > [6 5 6 7 0 0 0 0]\n",
      "    predicted> [6 5 6 7 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.14538268744945526\n",
      "  sample 1\n",
      "    input    > [8 4 5 9 4 0 0 0]\n",
      "    predicted> [8 4 5 9 4 1 0 0 0 0 0]\n",
      "  sample 2\n",
      "    input    > [9 9 5 7 0 0 0 0]\n",
      "    predicted> [9 9 5 7 1 0 0 0 0 0 0]\n",
      "  sample 3\n",
      "    input    > [2 5 8 8 5 3 2 8]\n",
      "    predicted> [2 5 8 8 5 3 2 8 1 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch ==0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}'.format(i+1))\n",
    "                print('    input    > {}'.format(inp))\n",
    "                print('    predicted> {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.1490 after 300100 examples (batch_size = <tf.Variable 'Variable_2:0' shape=(10,) dtype=float32_ref>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cc5daf39b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size = {})'.format(loss_track[-1], len(loss_track)*batch_size, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
